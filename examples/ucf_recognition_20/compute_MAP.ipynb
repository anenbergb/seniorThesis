{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RBF SVM using only Bag of Visual words IDTF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, numpy as np\n",
    "sys.path.append(\"/afs/cs.stanford.edu/u/anenberg/scr/caffe/python/\")\n",
    "import caffe, os\n",
    "import lmdb\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "# location of the list that was used to create LMDB for training/testing\n",
    "full_list = '../../data/ucf_recognition_20/lists/sampled_t1_p10_fullpath_all_list.txt'\n",
    "train_list = '../../data/ucf_recognition_20/lists/sampled_t1_p10_fullpath_train_list.txt'\n",
    "train_list = '../../data/ucf_recognition_20/lists/sampled_t1_p10_fullpath_test_list.txt'\n",
    "\n",
    "num_train = 23924\n",
    "num_test = 11190\n",
    "num_frames = 35114\n",
    "num_classes = 20 # the number of classes\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_bov = np.load('./bov_train.npz')\n",
    "train_df = pd.DataFrame(train_bov['data'])\n",
    "train_df['video_name'] = train_bov['video_name']\n",
    "train_df['true_label'] = train_bov['true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_bov['data']\n",
    "y_train = train_bov['true_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bov = np.load('./bov_test.npz')\n",
    "test_df = pd.DataFrame(test_bov['data'])\n",
    "test_df['video_name'] = test_bov['video_name']\n",
    "test_df['true_label'] = test_bov['true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_bov['data']\n",
    "y_test = test_bov['true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2765"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]+X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train 1-vs-all SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "estimator = OneVsRestClassifier(LinearSVC(random_state=0, C=100, loss='l2', penalty='l2'))\n",
    "classifier = estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_scores_df(classifier, X, y):\n",
    "    scores = classifier.decision_function(X)\n",
    "    df = pd.DataFrame(scores)\n",
    "    df['true_label'] = y\n",
    "    df['predicted_label'] = np.argmax(scores,axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_classic_average_precision(scores_data, class_id):\n",
    "    # given a class_id compute the average precision for that class\n",
    "    df = scores_data[[class_id, 'true_label']]\n",
    "    df = df.sort(class_id, ascending=False)\n",
    "    df['match'] = (df.true_label == class_id)\n",
    "    df['precision'] = np.cumsum(df.match)/np.arange(1, len(scores_data) + 1)\n",
    "    npos = sum(df.match)\n",
    "    df['precision_match'] = (df.match)*df.precision\n",
    "    ap = sum(df.precision_match)/npos\n",
    "    return ap\n",
    "\n",
    "def compute_rect_average_precision(scores_data, class_id):\n",
    "    # given a class_id compute the average precision for that class\n",
    "    df = scores_data[[class_id, 'true_label', 'predicted_label']]\n",
    "    df = df.sort(class_id, ascending=False)\n",
    "    df['match'] = (df.true_label == class_id)\n",
    "    df['precision'] = np.cumsum(df.match)/np.arange(1, len(scores_data) + 1)\n",
    "    df['recall'] = np.cumsum(df.match)/np.sum(df.true_label == class_id)\n",
    "    df['delta_recall'] = np.diff(np.append([0], df.recall.values)) #delta_recall(i) = recall(i)-recall(i-1)\n",
    "    df['rect_area'] = df['precision'] * df['delta_recall']\n",
    "    return sum(df.rect_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean_average_precision(scores_data):\n",
    "    average_precision = [] # list to hold average_precision\n",
    "    for class_id in range(num_classes):\n",
    "        ca = compute_classic_average_precision(scores_data, class_id)\n",
    "        average_precision.append(ca)\n",
    "    return np.mean(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_scores = compute_scores_df(classifier,X_test,y_test)\n",
    "average_precision = [] # list to hold average_precision\n",
    "\n",
    "for class_id in range(num_classes):\n",
    "    ca = compute_classic_average_precision(test_scores, class_id)\n",
    "    average_precision.append(ca)\n",
    "    \n",
    "#average_precision = [x if not np.isnan(x) else 0 for x in average_precision]\n",
    "#labels_as_text = [categories[i] for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.980090\n",
      "Accuracy: 0.979882\n"
     ]
    }
   ],
   "source": [
    "print 'MAP: %2f'%np.mean(average_precision)\n",
    "# What was the accuracy?\n",
    "print 'Accuracy: %2f' % np.mean(test_scores.true_label == test_scores.predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.980090\n",
      "Accuracy: 0.979882\n"
     ]
    }
   ],
   "source": [
    "average_precision = [] # list to hold average_precision\n",
    "\n",
    "for class_id in range(num_classes):\n",
    "    ca = compute_rect_average_precision(test_scores, class_id)\n",
    "    average_precision.append(ca)\n",
    "    \n",
    "print 'MAP: %2f'%np.mean(average_precision)\n",
    "# What was the accuracy?\n",
    "print 'Accuracy: %2f' % np.mean(test_scores.true_label == test_scores.predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add pre-trained CNN features to BoV vectors, and train SVM\n",
    "## First, get frame labels from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of frames in the list 35114, number of videos in list 2763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_label_from_list(list_filename):\n",
    "    df = pd.read_csv(list_filename, delimiter= ' ', header = None, names = ['filename', 'class_id'])\n",
    "    return df\n",
    "\n",
    "frame_df =  get_label_from_list(full_list)\n",
    "labels = frame_df.class_id.values\n",
    "frame_df['video_name'] = frame_df.filename.apply(lambda x: x.split('/')[-2])\n",
    "frame_df['frame_number'] = frame_df.filename.apply(lambda x: x.split('/')[-1])\n",
    "print \"number of frames in the list %d, number of videos in list %d\" % (len(frame_df),len(frame_df.video_name.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the cnn features using \"python extract_cnn_features.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cnn = np.load('./cnn_features.npz')['data']\n",
    "all_cnn_df = pd.DataFrame(all_cnn)\n",
    "all_cnn_df['video_name'] = frame_df.video_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train an SVM and measure mAP using only the cnn features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_cnn = all_cnn_df[all_cnn_df.video_name.isin(train_df.video_name[:-1])].as_matrix(columns=range(4096))\n",
    "X_test_cnn = all_cnn_df[all_cnn_df.video_name.isin(test_df.video_name[:-1])].as_matrix(columns=range(4096))\n",
    "y_train_cnn = y_train[:-1]\n",
    "y_test_cnn = y_test[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator_cnn = OneVsRestClassifier(LinearSVC(random_state=0, C=100, loss='l2', penalty='l2'))\n",
    "classifier_cnn = estimator_cnn.fit(X_train_cnn, y_train_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.070348\n",
      "Accuracy: 0.055687\n"
     ]
    }
   ],
   "source": [
    "test_scores_cnn = compute_scores_df(classifier_cnn,X_test_cnn,y_test_cnn)\n",
    "print 'MAP: %2f'% compute_mean_average_precision(test_scores_cnn)\n",
    "# What was the accuracy?\n",
    "print 'Accuracy: %2f' % np.mean(test_scores_cnn.true_label == test_scores_cnn.predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#Join the BoV features and CNN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df2 = train_df[:-1]\n",
    "test_df2 = test_df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_joined_df = pd.merge(test_df2,all_cnn_df,how='left', on='video_name')\n",
    "train_joined_df = pd.merge(train_df2,all_cnn_df,how='left', on='video_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_index(x):\n",
    "    \"\"\"\n",
    "    only works if there are fewer columns in the left df.\n",
    "    \"\"\"\n",
    "    new_x = x\n",
    "    if type(x)==str:\n",
    "        if '_x' in x:\n",
    "            new_x = int(x[:-2])\n",
    "        elif '_y' in x:\n",
    "            new_x = 16000+int(x[:-2])\n",
    "    return new_x\n",
    "        \n",
    "test_joined_df.rename(columns=new_index, inplace=True)\n",
    "train_joined_df.rename(columns=new_index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train an SVM and measure MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2 = train_joined_df.as_matrix(columns=range(20096))\n",
    "X_test2 = test_joined_df.as_matrix(columns=range(20096))\n",
    "y_train2 = np.array(train_joined_df.true_label)\n",
    "y_test2 = np.array(test_joined_df.true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator2 = OneVsRestClassifier(LinearSVC(random_state=0, C=100, loss='l2', penalty='l2'))\n",
    "classifier2 = estimator.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.924445\n",
      "Accuracy: 0.938389\n"
     ]
    }
   ],
   "source": [
    "test_scores2 = compute_scores_df(classifier2,X_test2,y_test2)\n",
    "print 'MAP: %2f'% compute_mean_average_precision(test_scores2)\n",
    "# What was the accuracy?\n",
    "print 'Accuracy: %2f' % np.mean(test_scores2.true_label == test_scores2.predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
